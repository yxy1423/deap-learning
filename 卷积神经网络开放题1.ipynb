{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87CC794C249F4CE188AD39B775DD1283",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 卷积神经网络开放题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6CC908D90834F39897857E572B228BD",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 数据集\n",
    "本次开放题将与课程内容保持一致，将使用图像数据集Fashion-MNIST [1] 进行计算机视觉任务的设计，该数据集由衣服、鞋子等服饰组成，共10个类别。\n",
    "\n",
    "这里简介将此数据集转换成卷积神经网络所需要的输入格式的方法：\n",
    "\n",
    "## 加载数据集\n",
    "\n",
    "首先导入本作业需要的包或模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2485EB5129604290A8A6997F1BD959C2",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96B1F57BDC27460B8813B1BAA85B2C91",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "通过`load_data_fashion_mnist`函数对数据集进行加载，另外函数还指定了参数`transform = transforms.ToTensor()`使所有数据转换为`Tensor`，如果不进行转换则返回的是PIL图片。`transforms.ToTensor()`将尺寸为 (H x W x C) 且数据位于 [0, 255] 的PIL图片或者数据类型为`np.uint8`的NumPy数组转换为尺寸为 (C x H x W) 且数据类型为`torch.float32`且位于 [0.0, 1.0] 的`Tensor`。\n",
    "\n",
    "我们将在训练数据集上训练模型，并将训练好的模型在测试数据集上评价模型的表现。函数中`mnist_train`是`torch.utils.data.Dataset`的子类，所以我们可以将其传入`torch.utils.data.DataLoader`来创建一个读取小批量数据样本的`DataLoader`实例。\n",
    "\n",
    "在实践中，数据读取经常是训练的性能瓶颈，特别当模型较简单或者计算硬件性能较高时。PyTorch的`DataLoader`中一个很方便的功能是允许使用多进程来加速数据读取。这里我们通过参数`num_workers`来设置进程读取数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "B27EC0CC4BE04EE784C5B1709DE8A9F0",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data_fashion_mnist(batch_size, resize=None, root=\"/home/kesci/input/FashionMNIST2065/\"):\n",
    "    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "\n",
    "    transform = torchvision.transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_iter, test_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "998590ABF38C45C78E789B6114D4BA55",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "对于AlexNet，我们需要将 Fashion-MNIST 数据集的图像高和宽扩大到224，这个可以通过在`load_data_fashion_mnist`中传入`Resize`来实现，这边设置数据的`batch_size`为128。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1CAD37F80172425585602A2603B55935",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3F9B18D7B324482B87552DC2F85FE886",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Fashion-MNIST中一共包括了10个类别，分别为t-shirt（T恤）、trouser（裤子）、pullover（套衫）、dress（连衣裙）、coat（外套）、sandal（凉鞋）、shirt（衬衫）、sneaker（运动鞋）、bag（包）和ankle boot（短靴）。以下函数可以将数值标签转成相应的文本标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CDB627CAEF934CACA1C892E62E6661BF",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_fashion_mnist_labels(labels):\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    return [text_labels[int(i)] for i in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DBBF22FE7994F69801387BA35EADF22",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "下面定义一个可以在一行里画出多张图像和对应标签的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "710431E0A0F148AA824DA10029AAED23",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_fashion_mnist(images, labels):\n",
    "    \"\"\"Use svg format to display plot in jupyter\"\"\"\n",
    "    display.set_matplotlib_formats('svg')\n",
    "    # 这里的_表示我们忽略（不使用）的变量\n",
    "    _, figs = plt.subplots(1, len(images), figsize=(12, 12))\n",
    "    for f, img, lbl in zip(figs, images, labels):\n",
    "        f.imshow(img.view((224, 224)).numpy())\n",
    "        f.set_title(lbl)\n",
    "        f.axes.get_xaxis().set_visible(False)\n",
    "        f.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9989FA74F34545608F888AE5FCAA8393",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "读取训练数据集中第一个`batch`的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0DB5E5D5D3734DB98320B9E074D43356",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = iter(train_iter)\n",
    "images, labels = next(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5CB466943BE46ACBA2AD08F35C2C2CC",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "现在，我们看一下训练数据集中前10个样本的图像内容和文本标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4BA010F52C054BB39AD024A9FEE7F954",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.kesci.com/rt_upload/4BA010F52C054BB39AD024A9FEE7F954/q6am9zeok8.svg\">"
      ],
      "text/plain": [
       "<Figure size 864x864 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = get_fashion_mnist_labels(labels)\n",
    "show_fashion_mnist(images[:10], labels[:10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0E1F3F3156CB4C599ECC4B4841226912",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 卷积神经网络（CNN）\n",
    "\n",
    "对于计算机视觉的分类任务，在很长一段时间里流行的是研究者通过经验与智慧所设计并生成的手工特征。这类图像分类研究的主要流程是：\n",
    "\n",
    "1. 获取图像数据集；\n",
    "2. 使用已有的特征提取函数生成图像的特征；\n",
    "3. 使用机器学习模型对图像的特征分类。\n",
    "\n",
    "卷积神经网络就是含卷积层的神经网络，深度卷积神经网络的兴起改变了计算机视觉任务中手工设计的特征的传统，引领了诸多影响深远的研究。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5094457635E64A7CBA319089C2F73E16",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## LeNet\n",
    "\n",
    "\n",
    "\n",
    "LeNet [2] 作为一个早期用来识别手写数字图像的卷积神经网络，展示了通过梯度下降训练卷积神经网络可以达到手写数字识别在当时最先进的结果。如下图所示：\n",
    "\n",
    "\n",
    "![LeNet模型](https://d2l.ai/_images/lenet.svg)\n",
    "\n",
    "\n",
    "LeNet的模型结构分为卷积层块和全连接层块两个部分：\n",
    "\n",
    "- 卷积层保留输入形状，使图像的像素在高和宽两个方向上的相关性均可能被有效识别，并且通过滑动窗口将同一卷积核与不同位置的输入重复计算，从而避免参数尺寸过大。\n",
    "\n",
    "- 全连接层块将卷积层块的输出中每个样本变平（flatten），即输入形状将变成二维，其中第一维是小批量中的样本，第二维是每个样本变平后的向量表示，从而进行分类。\n",
    "\n",
    "\n",
    "\n",
    "## AlexNet\n",
    "\n",
    "2012年，AlexNet [3] 横空出世，使用了8层卷积神经网络，并以很大的优势赢得了ImageNet 2012图像识别挑战赛。\n",
    "\n",
    "AlexNet与LeNet的设计理念非常相似，但相对较小的LeNet相比，AlexNet包含5层卷积和2层全连接隐藏层，以及1个全连接输出层，模型参数也大大增加。由于早期显存的限制，最早的AlexNet使用双数据流的设计，使一个GPU只需要处理一半模型。如下图所示：\n",
    "\n",
    "![AlexNet模型](https://tangshusen.me/Dive-into-DL-PyTorch/img/chapter05/5.6_alexnet.png)\n",
    "\n",
    "AlexNet首次证明了神经网络以端到端（end-to-end）的方式学习到的特征可以超越手工设计的特征，从而一举打破计算机视觉研究的前状。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4F3514A6E3774CE2876BF7A2056AE919",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 问题一：\n",
    "- 阅读提出上述两种网络的相关论文，试从数据集的预处理、激活函数的使用、训练方法的改进以及模型结构的变化等角度，从理论层面分析比较LeNet与AlexNet的结构差异，并尝试解释AlexNet为什么会具有对计算机视觉任务优越的处理性能。\n",
    "- AlexNet对Fashion-MNIST数据集来说可能过于复杂，请尝试对模型进行简化来使训练更快，同时保证分类准确率（accuracy）不明显下降（不低于85%），并将简化后的结构、节省的训练时间以及下降的准确率等相关指标以表格的形式进行总结分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6709F79955B04F528BEEF779255FCC93",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, 11, 4), # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2), # kernel_size, stride\n",
    "            # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。\n",
    "            # 前两个卷积层后不使用池化层来减小输入的高和宽\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "         # 这里全连接层的输出个数比LeNet中的大数倍。使用丢弃层来缓解过拟合\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*5*5, 4096),#两个参数：输入神经元个数，输出神经元个数；256：输入通道数，5*5输入map的宽和高\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            #由于使用CPU镜像，精简网络，若为GPU镜像可添加该层\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            # 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "            nn.Linear(4096, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):#把上面两个模块self.conv和self.fc连接起来\n",
    "#self.conv的输出是一个四维张量：batchsize*out_channels*height*width\n",
    "#self.fc的输入需要的是一个二维张量：batchsize*hiddens\n",
    "#所以本函数需要做一个reshape的工作\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))#img.shape[0]=batchsize\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "76F5E70F16E14AF09AFB15FD737A8004",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        # 如果没指定device就使用net的device\n",
    "        device = list(net.parameters())[0].device \n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval() # 评估模式, 这会关闭dropout\n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train() # 改回训练模式\n",
    "            else: # 自定义的模型, 3.13节之后不会用到, 不考虑GPU\n",
    "                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
    "                    # 将is_training设置成False\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "    \n",
    "def train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):\n",
    "    net = net.to(device)\n",
    "    print(\"training on \", device)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "34F7F3E1B90C48BFBC0C74356BDC504C",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.6038, train acc 0.771, test acc 0.853, time 131.1 sec\n",
      "epoch 2, loss 0.3336, train acc 0.876, test acc 0.876, time 131.0 sec\n",
      "epoch 3, loss 0.2880, train acc 0.893, test acc 0.886, time 131.3 sec\n"
     ]
    }
   ],
   "source": [
    "net=AlexNet()\n",
    "lr, num_epochs = 0.001, 3#相比LeNet,我们把AlexNet的学习率调小了\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "#d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\n",
    "train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "5B4FAD3D402B45948B05F17C769F6235",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#简化的AlexNet网络\n",
    "class AlexNet1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet1, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, 11, 4), # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2), # kernel_size, stride\n",
    "            # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。\n",
    "            # 前两个卷积层后不使用池化层来减小输入的高和宽\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "           # nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            #nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "         # 这里全连接层的输出个数比LeNet中的大数倍。使用丢弃层来缓解过拟合\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*5*5, 4096),#两个参数：输入神经元个数，输出神经元个数；256：输入通道数，5*5输入map的宽和高\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            #由于使用CPU镜像，精简网络，若为GPU镜像可添加该层\n",
    "            #nn.Linear(4096, 4096),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "\n",
    "            # 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "            nn.Linear(4096, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):#把上面两个模块self.conv和self.fc连接起来\n",
    "#self.conv的输出是一个四维张量：batchsize*out_channels*height*width\n",
    "#self.fc的输入需要的是一个二维张量：batchsize*hiddens\n",
    "#所以本函数需要做一个reshape的工作\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))#img.shape[0]=batchsize\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "5CD1BAEAF61242D48804981E93C484B6",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.5091, train acc 0.811, test acc 0.871, time 110.5 sec\n",
      "epoch 2, loss 0.3005, train acc 0.886, test acc 0.891, time 109.7 sec\n",
      "epoch 3, loss 0.2558, train acc 0.904, test acc 0.894, time 110.5 sec\n"
     ]
    }
   ],
   "source": [
    "net=AlexNet1()\n",
    "lr, num_epochs = 0.001, 3#相比LeNet,我们把AlexNet的学习率调小了\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CA7F6A308BF48CEAB9CC73FDD933F71",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## VGG\n",
    "\n",
    "AlexNet在LeNet的基础上增加了3个卷积层，同时对网络的卷积窗口、输出通道数和构造顺序均做了大量的调整。AlexNet指明了深度卷积神经网络可以取得出色的结果，基于这一个理念，牛津大学的实验室Visual Geometry Group实验室提出了VGG [4] 网络，提供了通过重复使用简单的基础块来构建深度模型的思路。VGG每个基础块组成规律是：连续使用数个相同的填充为1、窗口形状为$3\\times 3$的卷积层后接上一个步幅为2、窗口形状为$2\\times 2$的最大池化层。卷积层保持输入的高和宽不变，而池化层则对其减半。如下图所示：\n",
    "\n",
    "![VGG模型](https://boyuai.oss-cn-shanghai.aliyuncs.com/disk/YouthAI%E7%A7%8B%E5%AD%A3%E6%80%9D%E7%BB%B4%E7%8F%AD-%E4%B8%8A%E8%AF%BE%E8%A7%86%E9%A2%91/vgg.jpg)\n",
    "\n",
    "可以看到，每次经过基础块以后，网络会将输入的高和宽减半，直到最终高和宽变成7后传入全连接层。与此同时，输出通道数每次翻倍，直到变成512。因为每个卷积层的窗口大小一样，VGG这种高和宽减半以及通道翻倍的设计使得多数卷积层都有相同的模型参数尺寸和计算复杂度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17EF548115E14894860A16C6032B5B31",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 问题二：\n",
    "- LeNet与AlexNet在接近图像输入的卷积模块中都引入了较大尺寸的卷积核，如$5\\times 5$或者$7\\times 7$的卷积窗口来捕捉更大范围的图像信息，试分析VGG每个基础块的固定设计是否会影响到图像的粗粒度信息提取，并且对比不同结构模块输出的特征图进行对比。\n",
    "- 尝试将Fashion-MNIST中图像的高和宽由224改为96，试分析VGG网络的参数变化情况，并且对比模型训练时间、分类准确率（accuracy）等实验指标受到的影响，以表格的形式进行总结分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "F3E5A8481119496C806E05F43AD3100D",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vgg_block(num_convs, in_channels, out_channels): #卷积层个数，输入通道数，输出通道数\n",
    "    blk = []\n",
    "    for i in range(num_convs):\n",
    "        if i == 0:\n",
    "            blk.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        else:\n",
    "            blk.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        blk.append(nn.ReLU())\n",
    "    blk.append(nn.MaxPool2d(kernel_size=2, stride=2)) # 这里会使宽高减半\n",
    "    return nn.Sequential(*blk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "90D0FB199C7C4AC088F7512E8EE4B95C",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#conv_arch = ((1, 1, 64), (1, 64, 128), (2, 128, 256), (2, 256, 512), (2, 512, 512))\n",
    "#conv_arch = ((1, 1, 32), (1, 32, 64), (2, 64, 128), (2, 128, 256), (2, 256, 256))\n",
    "conv_arch = ((1, 1, 4), (1, 4, 8), (2, 8, 16), (2, 16, 32), (2, 32, 32))\n",
    "# 经过5个vgg_block, 宽高会减半5次, 变成 224/32 = 7\n",
    "#fc_features = 512 * 7 * 7 # c * w * h\n",
    "fc_features = 32 * 7 * 7 # c * w * h\n",
    "#fc_hidden_units = 4096 # 任意\n",
    "fc_hidden_units = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "C39EFA099D084823A13044EC061F595F",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FlattenLayer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlattenLayer, self).__init__()\n",
    "    def forward(self, x): # x shape: (batch, *, *, ...)\n",
    "        return x.view(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DF6FEBE92FB640CF846E7B11A21D8425",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vgg(conv_arch, fc_features, fc_hidden_units=4096):#conv_arch：每个VGGblock的参数设置\n",
    "    net = nn.Sequential()\n",
    "    # 卷积层部分\n",
    "    for i, (num_convs, in_channels, out_channels) in enumerate(conv_arch):\n",
    "        # 每经过一个vgg_block都会使宽高减半\n",
    "        net.add_module(\"vgg_block_\" + str(i+1), vgg_block(num_convs, in_channels, out_channels))#.add_module：拼接\n",
    "    # 全连接层部分\n",
    "    net.add_module(\"fc\", nn.Sequential(\n",
    "                                 #d2l.FlattenLayer(),#展平\n",
    "                                 FlattenLayer(),#展平\n",
    "                                 nn.Linear(fc_features, fc_hidden_units),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.5),\n",
    "                                 nn.Linear(fc_hidden_units, fc_hidden_units),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.5),\n",
    "                                 nn.Linear(fc_hidden_units, 10)\n",
    "                                ))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "1EADE57103244AF282859AB8BB56A82D",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 1.9261, train acc 0.260, test acc 0.642, time 74.8 sec\n",
      "epoch 2, loss 1.0502, train acc 0.598, test acc 0.698, time 75.1 sec\n",
      "epoch 3, loss 0.8939, train acc 0.665, test acc 0.720, time 75.0 sec\n",
      "epoch 4, loss 0.8243, train acc 0.690, test acc 0.734, time 75.1 sec\n",
      "epoch 5, loss 0.7792, train acc 0.708, test acc 0.740, time 75.1 sec\n",
      "epoch 6, loss 0.7455, train acc 0.720, test acc 0.748, time 74.9 sec\n",
      "epoch 7, loss 0.7188, train acc 0.731, test acc 0.755, time 74.9 sec\n",
      "epoch 8, loss 0.6998, train acc 0.739, test acc 0.757, time 75.1 sec\n",
      "epoch 9, loss 0.6787, train acc 0.744, test acc 0.765, time 74.9 sec\n",
      "epoch 10, loss 0.6578, train acc 0.753, test acc 0.764, time 75.0 sec\n"
     ]
    }
   ],
   "source": [
    "net = vgg(conv_arch, fc_features, fc_hidden_units)\n",
    "batch_size=16\n",
    "#batch_size = 64\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "#train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)\n",
    "\n",
    "lr, num_epochs = 0.00001, 10\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "#d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\n",
    "train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "5EE5A5F77AB749349A227C15FC91E99E",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#改变fashionminst数据集的图片大小为96\n",
    "batch_size=16\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "59C730ADB2C449F883D30147A42F1E8D",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv_arch = ((1, 1, 4), (1, 4, 8), (2, 8, 16), (2, 16, 32), (2, 32, 32))\n",
    "# 经过5个vgg_block, 宽高会减半5次, 变成 96/32 = 3\n",
    "fc_features = 32* 3* 3 # c * w * h\n",
    "fc_hidden_units = 256 # 任意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "9CA0EB8B48464785A5E1C57917EA816D",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.9703, train acc 0.624, test acc 0.772, time 75.0 sec\n",
      "epoch 2, loss 0.5821, train acc 0.781, test acc 0.813, time 74.7 sec\n",
      "epoch 3, loss 0.4940, train acc 0.817, test acc 0.836, time 74.8 sec\n",
      "epoch 4, loss 0.4440, train acc 0.835, test acc 0.852, time 75.1 sec\n",
      "epoch 5, loss 0.4105, train acc 0.848, test acc 0.856, time 75.1 sec\n"
     ]
    }
   ],
   "source": [
    "net = vgg(conv_arch, fc_features, fc_hidden_units)\n",
    "\n",
    "lr, num_epochs = 0.0001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BDCFE6F262641F0B869122CB976A2A8",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3F8AC63D06C14BF6894F6C7C1FCD6137",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## NiN\n",
    "\n",
    "之前介绍的LeNet、AlexNet和VGG在设计上的共同之处是：先以由卷积层构成的模块充分抽取空间特征，再以由全连接层构成的模块来输出分类结果。其中，AlexNet和VGG对LeNet的改进主要在于如何对这两个模块加宽（增加通道数）和加深。网络中的网络（NiN）[5] 提出了另外一个思路，即串联多个由卷积层和“全连接”层构成的小网络来构建一个深层网络。\n",
    "\n",
    "卷积层的输入和输出通常是四维数组（样本，通道，高，宽），而全连接层的输入和输出则通常是二维数组（样本，特征）。如果想在全连接层后再接上卷积层，则需要将全连接层的输出变换为四维，$1\\times 1$卷积层可以看成全连接层，其中空间维度（高和宽）上的每个元素相当于样本，通道相当于特征。因此，NiN使用$1\\times 1$卷积层来替代全连接层，从而使空间信息能够自然传递到后面的层中去。下图对比了NiN同AlexNet和VGG等网络在结构上的主要区别。\n",
    "\n",
    "![左图是AlexNet和VGG的网络结构局部，右图是NiN的网络结构局部](http://zh.d2l.ai/_images/nin.svg)\n",
    "\n",
    "NiN块是NiN中的基础块。它由一个卷积层加两个充当全连接层的$1\\times 1$卷积层串联而成。其中第一个卷积层的超参数可以自行设置，而第二和第三个卷积层的超参数一般是固定的。\n",
    "\n",
    "\n",
    "## GoogLeNet\n",
    "\n",
    "在2014年的ImageNet图像识别挑战赛中，一个名叫GoogLeNet的网络结构大放异彩 [6] ，它虽然在名字上向LeNet致敬，但在网络结构上已经很难看到LeNet的影子。GoogLeNet吸收了NiN中网络串联网络的思想，并在此基础上做了很大改进。GoogLeNet中的基础卷积块叫作Inception块，得名于同名电影《盗梦空间》（Inception）。与上NiN块相比，这个基础块在结构上更加复杂，如下图所示：\n",
    "\n",
    "![Inception块的结构](http://zh.d2l.ai/_images/inception.svg)\n",
    "\n",
    "Inception块里有4条并行的线路。前3条线路使用窗口大小分别是$1\\times 1$、$3\\times 3$和$5\\times 5$的卷积层来抽取不同空间尺寸下的信息，其中中间2个线路会对输入先做$1\\times 1$卷积来减少输入通道数，以降低模型复杂度。第四条线路则使用$3\\times 3$最大池化层，后接$1\\times 1$卷积层来改变通道数。4条线路都使用了合适的填充来使输入与输出的高和宽一致。最后将每条线路的输出在通道维上连结，并输入接下来的层中去。Inception块中可以自定义的超参数是每个层的输出通道数，以此来控制模型复杂度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDA58F8944734924A3AAC545E79942FA",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 问题三：\n",
    "- 对比AlexNet、VGG和NiN、GoogLeNet的模型参数尺寸，从理论的层面分析为什么后两个网络可以显著减小模型参数尺寸？\n",
    "- GoogLeNet有数个后续版本，包括加入批量归一化层 [7]、对Inception块做调整 [8] 和加入残差连接 [9]，请尝试实现并运行它们，然后观察实验结果，以表格的形式进行总结分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "102B57F65ECF44C88E9F098298108E5C",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# GoogLeNet\n",
    "1. 由Inception基础块组成。  \n",
    "2. Inception块相当于⼀个有4条线路的⼦⽹络。它通过不同窗口形状的卷积层和最⼤池化层来并⾏抽取信息，并使⽤1×1卷积层减少通道数从而降低模型复杂度。   \n",
    "3. 可以⾃定义的超参数是每个层的输出通道数，我们以此来控制模型复杂度。 \n",
    "1×1卷积层的作用是减少通道数，降低模型复杂度（和NiN的1×1卷积层的作用不同，NiN的作用的当作全连接层使用）\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5l6uortw.png?imageView2/0/w/640/h/640)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "E9B45668FA1840F98C20EB3713D2869F",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    # c1 - c4为每条线路里的层的输出通道数\n",
    "    def __init__(self, in_c, c1, c2, c3, c4):\n",
    "        super(Inception, self).__init__()\n",
    "        # 线路1，单1 x 1卷积层\n",
    "        self.p1_1 = nn.Conv2d(in_c, c1, kernel_size=1)\n",
    "        # 线路2，1 x 1卷积层后接3 x 3卷积层\n",
    "        self.p2_1 = nn.Conv2d(in_c, c2[0], kernel_size=1)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)#用padding的方式保持形状不变\n",
    "        # 线路3，1 x 1卷积层后接5 x 5卷积层\n",
    "        self.p3_1 = nn.Conv2d(in_c, c3[0], kernel_size=1)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
    "        # 线路4，3 x 3最大池化层后接1 x 1卷积层\n",
    "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2d(in_c, c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "        p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)  # 在通道维上连结输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7D7985FB0E1431D8F6E05F57175032D",
    "jupyter": {},
    "mdEditEnable": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "###GoogLeNet模型\n",
    "完整模型结构  \n",
    "输入的图形大小为：1×96×96\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5l6x0fyyn.png?imageView2/0/w/640/h/640)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "25E188EF3668434B800F30C0BF5A0D01",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GlobalAvgPool2d(nn.Module):\n",
    "    # 全局平均池化层可通过将池化窗口形状设置成输入的高和宽实现\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x, kernel_size=x.size()[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "40EA8C51C01A4147B64C987630C4D964",
    "jupyter": {},
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape:  torch.Size([1, 64, 24, 24])\n",
      "output shape:  torch.Size([1, 192, 12, 12])\n",
      "output shape:  torch.Size([1, 480, 6, 6])\n",
      "output shape:  torch.Size([1, 832, 3, 3])\n",
      "output shape:  torch.Size([1, 1024, 1, 1])\n",
      "output shape:  torch.Size([1, 1024])\n",
      "output shape:  torch.Size([1, 10])\n",
      "training on  cuda\n",
      "epoch 1, loss 1.0111, train acc 0.607, test acc 0.793, time 615.1 sec\n",
      "epoch 2, loss 0.3862, train acc 0.858, test acc 0.857, time 614.6 sec\n",
      "epoch 3, loss 0.3285, train acc 0.876, test acc 0.884, time 614.2 sec\n",
      "epoch 4, loss 0.2912, train acc 0.892, test acc 0.891, time 615.8 sec\n",
      "epoch 5, loss 0.2644, train acc 0.901, test acc 0.905, time 613.4 sec\n"
     ]
    }
   ],
   "source": [
    "#b1：第一和第二个方框：抽取特征减少大小\n",
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "#b2：第3——第5个方框\n",
    "b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),#没有增加通道数，起到非线性的作用\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),#增加通道数，保持形状不改变\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),#196为输入通道数，64+128+32+32=256为c输出通道数，是下一个inception的输入通道数\n",
    "                   Inception(256, 128, (128, 192), (32, 96), 64),#256为输入通道数，128+192+96+64=480输出通道数\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),#128+192+96+64=480输入通道数下面同理\n",
    "                   Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "                   Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "                   Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "                   Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),\n",
    "                   Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "                   GlobalAvgPool2d())\n",
    "\n",
    "net = nn.Sequential(b1, b2, b3, b4, b5, \n",
    "                    FlattenLayer(), nn.Linear(1024, 10))\n",
    "\n",
    "net = nn.Sequential(b1, b2, b3, b4, b5, FlattenLayer(), nn.Linear(1024, 10))\n",
    "\n",
    "X = torch.rand(1, 1, 96, 96)\n",
    "\n",
    "for blk in net.children(): \n",
    "    X = blk(X)\n",
    "    print('output shape: ', X.shape)\n",
    "\n",
    "\n",
    "#batchsize=128\n",
    "batch_size = 16\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "#train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEB870D6751E4AEA8AFEF82C092E454B",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "加入批量归一化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "F450ED75716C4087ACE7606B874A79F4",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def batch_norm(is_training, X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
    "    #X：我们的标准化目标，是（全连接层仿射变换/卷积计算）的输出，我们希望把它标准化为期望是0，方差是1的X_hat\n",
    "    #momentum：超参数不需要学习，是一个动量\n",
    "    # 判断当前模式是训练模式还是预测模式\n",
    "    if not is_training:\n",
    "        # 如果是在预测模式下，直接使用传入的移动平均所得的均值和方差\n",
    "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
    "    else:\n",
    "        assert len(X.shape) in (2, 4)\n",
    "        if len(X.shape) == 2:\n",
    "            # 使用全连接层的情况，计算特征维上的均值和方差\n",
    "            mean = X.mean(dim=0)\n",
    "            var = ((X - mean) ** 2).mean(dim=0)\n",
    "        else:\n",
    "            # 使用二维卷积层的情况，计算通道维上（axis=1）的均值和方差。这里我们需要保持\n",
    "            # X的形状以便后面可以做广播运算\n",
    "            mean = X.mean(dim=0, keepdim=True).mean(dim=2, keepdim=True).mean(dim=3, keepdim=True)\n",
    "            var = ((X - mean) ** 2).mean(dim=0, keepdim=True).mean(dim=2, keepdim=True).mean(dim=3, keepdim=True)\n",
    "        # 训练模式下用当前的均值和方差做标准化\n",
    "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
    "        # 更新移动平均的均值和方差\n",
    "        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean\n",
    "        moving_var = momentum * moving_var + (1.0 - momentum) * var\n",
    "    Y = gamma * X_hat + beta  # 拉伸和偏移\n",
    "    return Y, moving_mean, moving_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "4A6E13DD328C47E2935B70B437CF5126",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):#用来维护一些学习参数和超参数\n",
    "    def __init__(self, num_features, num_dims):\n",
    "        #num_features：全连接层代表输出神经元个数，卷积层代表通道数\n",
    "        #num_dims：全连接层等于2，卷积层等于4\n",
    "        super(BatchNorm, self).__init__()\n",
    "        if num_dims == 2:\n",
    "            shape = (1, num_features) #全连接层输出神经元\n",
    "        else:\n",
    "            shape = (1, num_features, 1, 1)  #通道数\n",
    "        # 参与求梯度和迭代的拉伸和偏移参数，分别初始化成0和1\n",
    "        self.gamma = nn.Parameter(torch.ones(shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(shape))\n",
    "        # 不参与求梯度和迭代的变量，全在内存上初始化成0\n",
    "        self.moving_mean = torch.zeros(shape)\n",
    "        self.moving_var = torch.zeros(shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 如果X不在内存上，将moving_mean和moving_var复制到X所在显存上\n",
    "        if self.moving_mean.device != X.device:\n",
    "            self.moving_mean = self.moving_mean.to(X.device)\n",
    "            self.moving_var = self.moving_var.to(X.device)\n",
    "        # 保存更新过的moving_mean和moving_var, Module实例的traning属性默认为true, 调用.eval()后设成false\n",
    "        Y, self.moving_mean, self.moving_var = batch_norm(self.training, \n",
    "            X, self.gamma, self.beta, self.moving_mean,\n",
    "            self.moving_var, eps=1e-5, momentum=0.9)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "C4B2AAF0B8704F9FBE0E651299BEBB24",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape:  torch.Size([1, 64, 24, 24])\n",
      "output shape:  torch.Size([1, 192, 12, 12])\n",
      "output shape:  torch.Size([1, 480, 6, 6])\n",
      "output shape:  torch.Size([1, 832, 3, 3])\n",
      "output shape:  torch.Size([1, 1024, 1, 1])\n",
      "output shape:  torch.Size([1, 1024])\n",
      "output shape:  torch.Size([1, 10])\n",
      "training on  cuda\n",
      "epoch 1, loss 0.4528, train acc 0.834, test acc 0.874, time 962.7 sec\n",
      "epoch 2, loss 0.3070, train acc 0.889, test acc 0.903, time 960.8 sec\n",
      "epoch 3, loss 0.2626, train acc 0.904, test acc 0.890, time 961.4 sec\n",
      "epoch 4, loss 0.2305, train acc 0.916, test acc 0.900, time 961.1 sec\n",
      "epoch 5, loss 0.2153, train acc 0.921, test acc 0.909, time 962.4 sec\n"
     ]
    }
   ],
   "source": [
    "#b1：第一和第二个方框：抽取特征减少大小\n",
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   BatchNorm(64, num_dims=4),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "#b2：第3——第5个方框\n",
    "b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),#没有增加通道数，起到非线性的作用\n",
    "                   BatchNorm(64, num_dims=4),\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),#增加通道数，保持形状不改变\n",
    "                   BatchNorm(192, num_dims=4),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),#196为输入通道数，64+128+32+32=256为c输出通道数，是下一个inception的输入通道数\n",
    "                   BatchNorm(256, num_dims=4),\n",
    "                   Inception(256, 128, (128, 192), (32, 96), 64),#256为输入通道数，128+192+96+64=480输出通道数\n",
    "                   BatchNorm(480, num_dims=4),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),#128+192+96+64=480输入通道数下面同理\n",
    "                   BatchNorm(512, num_dims=4),\n",
    "                   Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "                   BatchNorm(512, num_dims=4),\n",
    "                   Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "                   BatchNorm(512, num_dims=4),\n",
    "                   Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "                   BatchNorm(528, num_dims=4),\n",
    "                   Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "                   BatchNorm(832, num_dims=4),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),\n",
    "                   BatchNorm(832, num_dims=4),\n",
    "                   Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "                   BatchNorm(1024, num_dims=4),\n",
    "                   GlobalAvgPool2d())\n",
    "\n",
    "net = nn.Sequential(b1, b2, b3, b4, b5,FlattenLayer(), nn.Linear(1024, 10))\n",
    "\n",
    "X = torch.rand(1, 1, 96, 96)\n",
    "\n",
    "for blk in net.children(): \n",
    "    X = blk(X)\n",
    "    print('output shape: ', X.shape)\n",
    "\n",
    "#batchsize=128\n",
    "batch_size = 16\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "#train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E38C679E82624B928DE31EDAA0BB0C64",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "基于[8]对Inception块做调整\n",
    "论文提出四个原则：\n",
    "原则１:设计网络的时候需要避免 representational bottlenecks;　什么意思呢?　文章中说： 层与层之间进行 information 传递时，要避免这个过程中的数据的extreme compression，也就是说，数据的 scale 不能减小的太快；（数据从输入到输出大致是减少的，这个变化过程一定要gently，而不是快速的，    一定是慢慢的变少。。。。。。）       当数据的维数extreme下降的时候，就相当于引入了 representational bottelneck.\n",
    "原则2：没有怎么看明白什么意思啊？复制过来。Higher dimensional representations are easier to process locally within a network. Increasing the activations per tile in a convolutional network allows for more \n",
    "disentangled features. The resulting networks will train faster.  （可以结合 figure7 下面的注释， 我感觉： 在高维表示时，对于局部的特征更容易处理，意思就是local 卷积，用1*1啦， 或3*3, 别用太大的）\n",
    "原则3： spatial aggregation can be done over lower dimensional embedding without much or any loss in representational power.    直接翻译真的不会翻译啊\n",
    "原则4： 应该均衡网络的宽度与深度；\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2B4BD8AAAAF4415854C583270BCA550",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "网络改进：\n",
    "1. 把大的卷积层分解为小的卷积层，提高计算效率：\n",
    "第一种：可以把一个5*5的卷积卷积层分解成两个 3*3 的卷积层。       \n",
    "一个细节就是：把底层的 filters 为m 时， 上层的filters 为 n 时，这时两层的小的卷积层的每一个filters 为多少呢？ 细节2： 当原来的 激活函数为线性激活函数时，现在变为两层的激活函数如何选择？（文中说明了全部使用 relu 激活函数会好一些）\n",
    "\n",
    "![Image Name](http://images2015.cnblogs.com/blog/961754/201706/961754-20170609114156012-76460819.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "C6447A3767E546CAA2FAA48030DC52AE",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Inception1(nn.Module):\n",
    "    # c1 - c4为每条线路里的层的输出通道数\n",
    "    def __init__(self, in_c, c1, c2, c3, c4):\n",
    "        super(Inception1, self).__init__()\n",
    "        # 线路1，单1 x 1卷积层\n",
    "        self.p1_1 = nn.Conv2d(in_c, c1, kernel_size=1)\n",
    "        # 线路2，1 x 1卷积层后接3 x 3卷积层\n",
    "        self.p2_1 = nn.Conv2d(in_c, c2[0], kernel_size=1)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)#用padding的方式保持形状不变\n",
    "        # 线路3，1 x 1卷积层后接两个3 x 3卷积层\n",
    "        self.p3_1 = nn.Conv2d(in_c, c3[0], kernel_size=1)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=3, padding=1)\n",
    "        self.p3_3 = nn.Conv2d(c3[1], c3[1], kernel_size=3, padding=1)\n",
    "        # 线路4，3 x 3最大池化层后接1 x 1卷积层\n",
    "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2d(in_c, c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        p3 = F.relu(self.p3_3(F.relu(self.p3_2(F.relu(self.p3_1(x))))))\n",
    "        p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)  # 在通道维上连结输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "47D5F3BE85064AC886CA13860E51AE34",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape:  torch.Size([1, 64, 24, 24])\n",
      "output shape:  torch.Size([1, 192, 12, 12])\n",
      "output shape:  torch.Size([1, 480, 6, 6])\n",
      "output shape:  torch.Size([1, 832, 3, 3])\n",
      "output shape:  torch.Size([1, 1024, 1, 1])\n",
      "output shape:  torch.Size([1, 1024])\n",
      "output shape:  torch.Size([1, 10])\n",
      "training on  cuda\n",
      "epoch 1, loss 0.9698, train acc 0.626, test acc 0.781, time 669.8 sec\n",
      "epoch 2, loss 0.4199, train acc 0.842, test acc 0.855, time 672.0 sec\n",
      "epoch 3, loss 0.3421, train acc 0.870, test acc 0.851, time 668.5 sec\n",
      "epoch 4, loss 0.3067, train acc 0.885, test acc 0.879, time 668.6 sec\n",
      "epoch 5, loss 0.2851, train acc 0.893, test acc 0.885, time 668.9 sec\n"
     ]
    }
   ],
   "source": [
    "#b1：第一和第二个方框：抽取特征减少大小\n",
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "#b2：第3——第5个方框\n",
    "b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),#没有增加通道数，起到非线性的作用\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),#增加通道数，保持形状不改变\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b3 = nn.Sequential(Inception1(192, 64, (96, 128), (16, 32), 32),#196为输入通道数，64+128+32+32=256为c输出通道数，是下一个inception的输入通道数\n",
    "                   Inception1(256, 128, (128, 192), (32, 96), 64),#256为输入通道数，128+192+96+64=480输出通道数\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b4 = nn.Sequential(Inception1(480, 192, (96, 208), (16, 48), 64),#128+192+96+64=480输入通道数下面同理\n",
    "                   Inception1(512, 160, (112, 224), (24, 64), 64),\n",
    "                   Inception1(512, 128, (128, 256), (24, 64), 64),\n",
    "                   Inception1(512, 112, (144, 288), (32, 64), 64),\n",
    "                   Inception1(528, 256, (160, 320), (32, 128), 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b5 = nn.Sequential(Inception1(832, 256, (160, 320), (32, 128), 128),\n",
    "                   Inception1(832, 384, (192, 384), (48, 128), 128),\n",
    "                   GlobalAvgPool2d())\n",
    "\n",
    "net1 = nn.Sequential(b1, b2, b3, b4, b5, FlattenLayer(), nn.Linear(1024, 10))\n",
    "\n",
    "X = torch.rand(1, 1, 96, 96)\n",
    "\n",
    "for blk in net1.children(): \n",
    "    X = blk(X)\n",
    "    print('output shape: ', X.shape)\n",
    "\n",
    "#batchsize=128\n",
    "batch_size = 16\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "#train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net1.parameters(), lr=lr)\n",
    "train_ch5(net1, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76C9A36234E9455E83F5162A6C8832DB",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    " 2.非对称分解：\n",
    "把一个 n*n 的卷积层分解为两个 1*N 和 N*1 的卷积层；         （文中说了这种分解在网络的开始几层效果垃圾， but is gives very good result on medium grid-sizes）\n",
    "![Image Name](http://images2015.cnblogs.com/blog/961754/201706/961754-20170609114204653-1728991877.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "883329A4698642158A2F4ABB5F0D6EC7",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Inception2(nn.Module):\n",
    "    # c1 - c4为每条线路里的层的输出通道数\n",
    "    def __init__(self, in_c, c1, c2, c3, c4):\n",
    "        super(Inception, self).__init__()\n",
    "        # 线路1，单1 x 1卷积层\n",
    "        self.p1_1 = nn.Conv2d(in_c, c1, kernel_size=1)\n",
    "        # 线路2，1 x 1卷积层后接3 x 3卷积层\n",
    "        self.p2_1 = nn.Conv2d(in_c, c2[0], kernel_size=1)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=(1,3), padding=1)#用padding的方式保持形状不变\n",
    "        self.p2_3 = nn.Conv2d(c2[1], c2[1], kernel_size=(3,1))\n",
    "        # 线路3，1 x 1卷积层后接两个3 x 3卷积层\n",
    "        self.p3_1 = nn.Conv2d(in_c, c3[0], kernel_size=1)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=(1,3), padding=1)\n",
    "        self.p3_3 = nn.Conv2d(c3[1], c3[1], kernel_size=(3,1))\n",
    "        self.p3_4 = nn.Conv2d(c3[1], c3[1], kernel_size=(1,3), padding=1)\n",
    "        self.p3_5 = nn.Conv2d(c3[1], c3[1], kernel_size=(3,1))\n",
    "        # 线路4，3 x 3最大池化层后接1 x 1卷积层\n",
    "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2d(in_c, c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_3(F.relu(self.p2_2(F.relu(self.p2_1(x))))))\n",
    "        p3 = F.relu(self.p3_5(F.relu(self.p3_4(F.relu(self.p3_3(F.relu(self.p3_2(F.relu(self.p3_1(x))))))))))\n",
    "        p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)  # 在通道维上连结输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "738BF3A662CC443A80DD352BD45E33BE",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#b1：第一和第二个方框：抽取特征减少大小\n",
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "#b2：第3——第5个方框\n",
    "b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),#没有增加通道数，起到非线性的作用\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),#增加通道数，保持形状不改变\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b3 = nn.Sequential(Inception2(192, 64, (96, 128), (16, 32), 32),#196为输入通道数，64+128+32+32=256为c输出通道数，是下一个inception的输入通道数\n",
    "                   Inception2(256, 128, (128, 192), (32, 96), 64),#256为输入通道数，128+192+96+64=480输出通道数\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b4 = nn.Sequential(Inception2(480, 192, (96, 208), (16, 48), 64),#128+192+96+64=480输入通道数下面同理\n",
    "                   Inception2(512, 160, (112, 224), (24, 64), 64),\n",
    "                   Inception2(512, 128, (128, 256), (24, 64), 64),\n",
    "                   Inception2(512, 112, (144, 288), (32, 64), 64),\n",
    "                   Inception2(528, 256, (160, 320), (32, 128), 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b5 = nn.Sequential(Inception2(832, 256, (160, 320), (32, 128), 128),\n",
    "                   Inception2(832, 384, (192, 384), (48, 128), 128),\n",
    "                   GlobalAvgPool2d())\n",
    "\n",
    "net2 = nn.Sequential(b1, b2, b3, b4, b5, d2l.FlattenLayer(), nn.Linear(1024, 10))\n",
    "\n",
    "X = torch.rand(1, 1, 96, 96)\n",
    "\n",
    "for blk in net2.children(): \n",
    "    X = blk(X)\n",
    "    print('output shape: ', X.shape)\n",
    "\n",
    "#batchsize=128\n",
    "batch_size = 16\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "#train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net2.parameters(), lr=lr)\n",
    "train_ch5(net2, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6D8B5343B74D4DC7848C216FD784A787",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "加入残差块[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "638862CDCD6C493F86B13F25D29F30B2",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Residual(nn.Module):  # 本类已保存在d2lzh_pytorch包中方便以后使用\n",
    "    #可以设定输出通道数、是否使用额外的1x1卷积层来修改通道数以及卷积层的步幅。\n",
    "    def __init__(self, in_channels, out_channels, use_1x1conv=False, stride=1):\n",
    "        super(Residual, self).__init__()\n",
    "        self.p1_1 = nn.Conv2d(in_c, c1, kernel_size=1)\n",
    "        # 线路2，1 x 1卷积层后接3 x 3卷积层\n",
    "        self.p2_1 = nn.Conv2d(in_c, c2[0], kernel_size=1)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)#用padding的方式保持形状不变\n",
    "        # 线路3，1 x 1卷积层后接两个3 x 3卷积层\n",
    "        self.p3_1 = nn.Conv2d(in_c, c3[0], kernel_size=1)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=3, padding=1)\n",
    "        self.p3_3 = nn.Conv2d(c3[1], c3[1], kernel_size=3, padding=1)\n",
    "        \n",
    "        #self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride)\n",
    "        #self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "            \n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        p1 = F.relu(self.bn1(self.p1_1(x))+X)\n",
    "        p2 = F.relu(self.bn2(self.p2_2(F.relu(self.p2_1(x))))+X)\n",
    "        p3 = F.relu(self.bn3(self.p3_3(F.relu(self.p3_2(F.relu(self.p3_1(x))))))+X)\n",
    "        #return torch.cat((p1, p2, p3), dim=1)  \n",
    "        #Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        #Y = self.bn2(self.conv2(Y))\n",
    "        return torch.cat((p1, p2, p3), dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "D47B0022A856460E844126C71FC9485C",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resnet_block(in_channels, out_channels, num_residuals, first_block=False):\n",
    "    #num_residuals残差快个数\n",
    "    if first_block:\n",
    "        assert in_channels == out_channels # 第一个模块的通道数同输入通道数一致\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(in_channels, out_channels, use_1x1conv=True, stride=2))\n",
    "        else:\n",
    "            blk.append(Residual(out_channels, out_channels))\n",
    "    return nn.Sequential(*blk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "19E3C1D62034429E867ED1A703CDD1EB",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#b1：第一和第二个方框：抽取特征减少大小\n",
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "#b2：第3——第5个方框\n",
    "b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),#没有增加通道数，起到非线性的作用\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),#增加通道数，保持形状不改变\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b3 = nn.Sequential(Inception1(192, 64, (96, 128), (16, 32), 32),#196为输入通道数，64+128+32+32=256为c输出通道数，是下一个inception的输入通道数\n",
    "                   Inception1(256, 128, (128, 192), (32, 96), 64),#256为输入通道数，128+192+96+64=480输出通道数\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b4 = nn.Sequential(Inception1(480, 192, (96, 208), (16, 48), 64),#128+192+96+64=480输入通道数下面同理\n",
    "                   Inception1(512, 160, (112, 224), (24, 64), 64),\n",
    "                   Inception1(512, 128, (128, 256), (24, 64), 64),\n",
    "                   Inception1(512, 112, (144, 288), (32, 64), 64),\n",
    "                   Inception1(528, 256, (160, 320), (32, 128), 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b5 = nn.Sequential(Inception1(832, 256, (160, 320), (32, 128), 128),\n",
    "                   Inception1(832, 384, (192, 384), (48, 128), 128),\n",
    "                   GlobalAvgPool2d())\n",
    "                   \n",
    "net3 = nn.Sequential(b1, b2, b3, b4, b5)\n",
    "net3.add_module(\"resnet_block1\", resnet_block(1024, 1024, 2, first_block=True))\n",
    "net3.add_module(\"resnet_block2\", resnet_block(1024, 512, 2))\n",
    "net3.add_module(\"resnet_block3\", resnet_block(512, 256, 2))\n",
    "net3.add_module(\"resnet_block4\", resnet_block(256, 256, 2))\n",
    "net3.add_module(\"global_avg_pool\", GlobalAvgPool2d()) # GlobalAvgPool2d的输出: (Batch, 512, 1, 1)\n",
    "net3.add_module(\"fc\", nn.Sequential(FlattenLayer(), nn.Linear(256, 10))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1C00C5323198446490944FCD715877CA",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.9511, train acc 0.633, test acc 0.636, time 5632.3 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net3.parameters(), lr=lr)\n",
    "train_ch5(net3, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBDF0F702333469D8FA63476FDC4B4C5",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 参考文献\n",
    "[1] Xiao, H., Rasul, K., & Vollgraf, R. (2017). Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. arXiv preprint arXiv:1708.07747.\n",
    "\n",
    "[2] LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278-2324.\n",
    "\n",
    "[3] Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems (pp. 1097-1105).\n",
    "\n",
    "[4] Simonyan, K., & Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556.\n",
    "\n",
    "[5] Lin, M., Chen, Q., & Yan, S. (2013). Network in network. arXiv preprint arXiv:1312.4400.\n",
    "\n",
    "[6] Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., & Anguelov, D. & Rabinovich, A.(2015). Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 1-9).\n",
    "\n",
    "[7] Ioffe, S., & Szegedy, C. (2015). Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167.\n",
    "\n",
    "[8] Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., & Wojna, Z. (2016). Rethinking the inception architecture for computer vision. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 2818-2826).\n",
    "\n",
    "[9] Szegedy, C., Ioffe, S., Vanhoucke, V., & Alemi, A. A. (2017, February). Inception-v4, inception-resnet and the impact of residual connections on learning. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 4, p. 12)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5CF3616CCDDB4465BB50FD0A0EC1C7A5",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 项目报告\n",
    "本次大作业的终审评估以项目报告作为重要依据，开放题报告的内容和排版要求请下载文件：\n",
    "\n",
    "\n",
    "[termproject2.zip](https://boyuai.oss-cn-shanghai.aliyuncs.com/disk/YouthAI%E7%A7%8B%E5%AD%A3%E6%80%9D%E7%BB%B4%E7%8F%AD-%E4%B8%8A%E8%AF%BE%E8%A7%86%E9%A2%91/termproject2.zip)\n",
    "\n",
    "需要注意的是，文件中：\n",
    "- `termproject.pdf`提供了项目报告的内容格式要求\n",
    "- `termproject_exp.pdf`提供了项目报告的内容排版样例\n",
    "\n",
    "\n",
    "推荐使用`LaTeX`软件进行报告的撰写，相关`.tex`以及`.sty`源文件一并附于文件夹中。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
